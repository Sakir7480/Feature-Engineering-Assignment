{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "                                    Feature Engineering\n",
        "1.What is a parameter?\n",
        "\n",
        ".A parameter is a variable or a value that is used to define or characterize a system, model, function, or process. The specific meaning of a parameter can vary depending on the context in which it is used.\n",
        "\n",
        "2.What is correlation?\n",
        "\n",
        ".Correlation is a statistical measure that describes the extent to which two variables change together. It indicates whether there is a relationship between the variables and the direction and strength of that relationship. Correlation is often used to assess the degree of association or dependence between variables.\n",
        "\n",
        ".What does negative correlation mean?\n",
        "\n",
        ".A negative correlation means that there is an inverse relationship between two variables: as one variable increases, the other tends to decrease. In other words, the variables move in opposite directions. This relationship is quantified by a correlation coefficient (typically denoted as\n",
        "r\n",
        "r), which ranges from -1 to 1.\n",
        "\n",
        "3.Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        ".Machine Learning (ML) is a subset of artificial intelligence (AI) that focuses on developing algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data, without being explicitly programmed. Instead of following rigid instructions, ML systems improve their performance over time by identifying patterns and relationships in data.\n",
        "\n",
        ".Main Components of Machine Learning:\n",
        "\n",
        ". Data: Data is the foundation of machine learning. It can be structured (e.g., tables, databases) or unstructured (e.g., images, text, audio).\n",
        "\n",
        ".Data is divided into:\n",
        "\n",
        "Training Data: Used to train the model.\n",
        "\n",
        "Validation Data: Used to tune the model and prevent overfitting.\n",
        "\n",
        "Test Data: Used to evaluate the model's performance on unseen data.\n",
        "\n",
        "4.How does loss value help in determining whether the model is good or not?\n",
        "\n",
        ".The loss value is a critical metric in machine learning that quantifies how well a model is performing during training and evaluation. It measures the difference between the model's predictions and the actual target values (ground truth). A lower loss value indicates that the model's predictions are closer to the true values, while a higher loss value indicates greater error.\n",
        "\n",
        "5.What are continuous and categorical variables?\n",
        "\n",
        ".In statistics and data science, variables are classified into different types based on the nature of the data they represent. Two fundamental types of variables are continuous variables and categorical variables. Understanding the distinction between these two is crucial for data analysis, modeling, and machine learning.\n",
        "\n",
        ". Continuous Variables: Continuous variables represent data that can take any value within a given range. They are typically measured and can include fractions or decimals. Continuous variables are often used in regression analysis and other statistical modeling techniques.\n",
        "\n",
        ".Categorical Variables: Categorical variables represent data that can be divided into distinct groups or categories. These variables are often used in classification tasks and are typically non-numeric, though they can be represented numerically for computational purposes.\n",
        "\n",
        "6.How do we handle categorical variables in Machine Learning? What are the common t echniques?\n",
        "\n",
        ".Handling categorical variables is a crucial step in machine learning because most algorithms require numerical input data. Categorical variables, which represent qualitative data (e.g., gender, color, or education level), must be converted into a numerical format before they can be used in models.\n",
        "\n",
        "7.What do you mean by training and testing a dataset?\n",
        "\n",
        ".Training and testing a dataset are two fundamental steps in machine learning and data science.\n",
        "\n",
        ".Training a Dataset\n",
        "\n",
        ".In this step, a machine learning model learns from a dataset.\n",
        "\n",
        "The training dataset contains input data and corresponding output labels (for supervised learning).\n",
        "\n",
        "The model identifies patterns and relationships in the data.\n",
        "\n",
        "The goal is to minimize error by adjusting the model's parameters.\n",
        "\n",
        "8.What is sklearn.preprocessing?\n",
        "\n",
        ".sklearn.preprocessing is a module in Scikit-Learn that provides functions for scaling, transforming, and normalizing data before feeding it into a machine learning model. Preprocessing is essential because many ML algorithms perform better when features have standardized values.\n",
        "\n",
        "9.What is a Test set?\n",
        "\n",
        ".A test set is a subset of data that is used to evaluate the performance of a machine learning model after it has been trained. It is a critical component of the model evaluation process and helps assess how well the model generalizes to unseen data.\n",
        "\n",
        "10.How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        ".Splitting Data for Model Fitting (Training and Testing) in Python\n",
        "To split data into training and testing sets in Python, we use train_test_split from sklearn.model_selection.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vwS3VvwZJWZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Example dataset\n",
        "X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n",
        "y = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
        "\n",
        "# Splitting into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training data:\", X_train)\n",
        "print(\"Testing data:\", X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J2bE-VpY5LB",
        "outputId": "276d7cb3-3f68-4c33-dd6b-002df78be4c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: [[ 6]\n",
            " [ 1]\n",
            " [ 8]\n",
            " [ 3]\n",
            " [10]\n",
            " [ 5]\n",
            " [ 4]\n",
            " [ 7]]\n",
            "Testing data: [[9]\n",
            " [2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".Approaching a Machine Learning Problem\n",
        "A structured approach to solving a machine learning problem ensures efficiency and accuracy. Hereâ€™s a step-by-step guide:\n",
        "\n",
        "11.Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        ".Exploratory Data Analysis (EDA) is a crucial step before training a machine learning model. It helps us understand the dataset, identify issues, and make informed preprocessing decisions to improve model performance.\n",
        "\n",
        ".Key Reasons for Performing EDA:\n",
        "\n",
        ".Understand the Data Structure\n",
        "\n",
        ".Detect Missing Values\n",
        "\n",
        ".Identify Outliers\n",
        "\n",
        "12.What is correlation?\n",
        "\n",
        ".Correlation is a statistical measure that describes the extent to which two variables change together. It quantifies the strength and direction of the relationship between two variables, indicating whether they tend to move in the same direction, opposite directions, or have no relationship at all.\n",
        "\n",
        "13.What does negative correlation mean?\n",
        "\n",
        ".Negative correlation is a statistical relationship between two variables where one increases while the other decreases.\n",
        "\n",
        ".It is measured by the correlation coefficient (r), which ranges from -1 to 1.\n",
        "\n",
        "A negative correlation means that when one variable goes up, the other goes down (and vice versa).\n",
        "\n",
        "14.How can you find correlation between variables in Python?\n",
        "\n",
        ".You can calculate correlation coefficients using Python's pandas and numpy libraries.\n",
        "\n",
        ".Using pandas .corr() Method\n",
        "The .corr() method computes the Pearson correlation coefficient (default).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qaKJ1cmkZO-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample dataset\n",
        "data = {\n",
        "    \"Temperature\": [30, 25, 20, 15, 10],  # Decreasing\n",
        "    \"Ice_Cream_Sales\": [100, 80, 60, 40, 20]  # Also decreasing\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Compute correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xelDA5hVcUZ8",
        "outputId": "f6abf882-db1f-4450-fb00-1f598cea5e09"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Temperature  Ice_Cream_Sales\n",
            "Temperature              1.0              1.0\n",
            "Ice_Cream_Sales          1.0              1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        ".Causation means that one event directly causes another event to happen. If A causes B, then changing A directly influences B.\n",
        "\n",
        "For example:\n",
        "\n",
        "Drinking more water causes better hydration.\n",
        "\n",
        "Increasing the speed of a car causes a decrease in the time to reach a destination.\n",
        "\n",
        ".Correlation Example:\n",
        "\n",
        "People who drink more coffee tend to have higher productivity.\n",
        "\n",
        "This does not mean that coffee causes productivity.\n",
        "\n",
        "There might be a third factor, like people who wake up early drink coffee and are also more productive.\n",
        "\n",
        ". Causation Example:\n",
        "\n",
        "If you increase study time, your exam scores improve.\n",
        "\n",
        "Here, increasing study time directly causes higher scores.\n",
        "\n",
        "16.What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        ".An optimizer is an algorithm that adjusts the weights and biases of a machine learning model to minimize the loss function and improve accuracy. Optimizers are essential in training neural networks and deep learning models.\n",
        "\n",
        ".Types of Optimizers in Machine Learning\n",
        "\n",
        ".Gradient Descent (GD)\n",
        "\n",
        ".Stochastic Gradient Descent (SGD)\n",
        "\n",
        ".Mini-Batch Gradient Descent\n",
        "\n",
        "17.What is sklearn.linear_model ?\n",
        "\n",
        ".sklearn.linear_model is a module in Scikit-Learn that provides various linear models for regression and classification tasks. It includes algorithms like Linear Regression, Logistic Regression, Ridge, Lasso, and more.\n",
        "\n",
        "18.What does model.fit() do? What arguments must be given?\n",
        "\n",
        ".model.fit() is a method in Scikit-Learn (and other ML libraries) used to train a machine learning model on a given dataset.\n",
        "\n",
        ".When you call .fit(), the model:\n",
        "\n",
        "Learns patterns from the training data.\n",
        "\n",
        "Adjusts its parameters (like weights in regression or coefficients in classification).\n",
        "\n",
        "Minimizes the loss function to improve accuracy.\n",
        "\n",
        "19.What does model.predict() do? What arguments must be given?\n",
        "\n",
        ".model.predict() is a method in Scikit-Learn used to make predictions on new/unseen data after a model has been trained using model.fit().\n",
        "\n",
        ".When you call .predict(), the model:\n",
        "\n",
        "Takes new input data (X_new).\n",
        "\n",
        "Applies learned patterns from training.\n",
        "\n",
        "Returns predicted values (output).\n",
        "\n",
        "20.What are continuous and categorical variables?\n",
        "\n",
        ".In machine learning and statistics, variables are classified into continuous and categorical types.\n",
        "\n",
        ".Continuous Variables\n",
        "\n",
        "Definition: A variable that can take infinite values within a range.\n",
        "\n",
        "Numeric and can have decimal points.\n",
        "\n",
        "Measured rather than counted.\n",
        "\n",
        ". Categorical Variables\n",
        "\n",
        "Definition: A variable that represents categories or labels.\n",
        "\n",
        "Can be nominal (no order) or ordinal (ordered).\n",
        "\n",
        "Often encoded as numbers (e.g., 0 = Male, 1 = Female).\n",
        "\n",
        "21.What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        ".Feature Scaling is the process of normalizing or standardizing numerical data so that all features have a similar scale. It helps improve the performance of machine learning algorithms by ensuring that no single feature dominates due to its large magnitude.\n",
        "\n",
        ".Why is Feature Scaling Important?\n",
        "\n",
        "Prevents Bias in ML Models\n",
        "\n",
        "Features with larger values may have higher influence in distance-based models (e.g., KNN, SVM).\n",
        "\n",
        "Speeds Up Gradient Descent\n",
        "\n",
        "Large feature values can cause slow convergence in optimization algorithms.\n",
        "\n",
        "Improves Model Accuracy\n",
        "\n",
        "Some ML models (e.g., Neural Networks) perform better when features are on a similar scale.\n",
        "\n",
        "22.How do we perform scaling in Python?\n",
        "\n",
        "How to Perform Feature Scaling in Python?\n",
        "\n",
        "Feature scaling in Python can be done using Scikit-Learnâ€™s preprocessing module.\n",
        "\n",
        " The three most common scaling techniques are:\n",
        "\n",
        "Min-Max Scaling (Normalization)\n",
        "\n",
        "Standardization (Z-score)\n",
        "\n",
        "Robust Scaling (Handles Outliers)\n",
        "\n",
        "23.What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        ".sklearn.preprocessing is a module in Scikit-Learn that provides functions to transform and preprocess data before feeding it into a machine learning model.\n",
        "\n",
        "ðŸ”¹ Why is it important?\n",
        "\n",
        "Machine learning models perform better when data is scaled, normalized, and encoded properly.\n",
        "\n",
        "Helps in handling missing values, categorical data, feature scaling, and polynomial feature expansion.\n",
        "\n",
        "24.How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        ".In machine learning, we split data into training and testing sets to evaluate model performance.\n",
        "\n",
        "Training Set: Used to train the model.\n",
        "Testing Set: Used to check model accuracy on unseen data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tdhGilOqcWrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Sample Data\n",
        "X = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])  # Features\n",
        "y = np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1])  # Target labels\n",
        "\n",
        "# Split data (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display results\n",
        "print(\"Training Features:\", X_train)\n",
        "print(\"Testing Features:\", X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJyr1AkFrff5",
        "outputId": "b798f453-9001-4612-8b03-f164118fb6a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features: [[ 6]\n",
            " [ 1]\n",
            " [ 8]\n",
            " [ 3]\n",
            " [10]\n",
            " [ 5]\n",
            " [ 4]\n",
            " [ 7]]\n",
            "Testing Features: [[9]\n",
            " [2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.Explain data encoding?\n",
        "\n",
        ".Data encoding is the process of converting categorical data into a numerical format so that machine learning models can understand and process it. Many ML algorithms work with numerical data, so categorical variables (like \"Red\", \"Blue\", \"Green\") must be encoded into numbers.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bgn2hjN1riT0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N3sVBsZJAWX"
      },
      "outputs": [],
      "source": []
    }
  ]
}